{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '181~ 360.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8aa62e9edf63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'181~ 360.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'main_category'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ratings'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'keywords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1989\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1990\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1991\u001b[1;33m                 \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1992\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '181~ 360.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = pd.read_csv('181~ 360.csv', encoding='utf-8', header=None, names=['names', 'main_category', 'ratings', 'keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>ratings</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이천 세계 도자 센터</td>\n",
       "      <td>4.75</td>\n",
       "      <td>전문  박물관</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>신세계 백화점 센텀시티</td>\n",
       "      <td>4.48</td>\n",
       "      <td>쇼핑 백화점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>미륵산</td>\n",
       "      <td>4.66</td>\n",
       "      <td>자연 공원 산 하이킹트레일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>성남 아트센터</td>\n",
       "      <td>4.62</td>\n",
       "      <td>즐길거리  랜드마크</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>관촉사</td>\n",
       "      <td>4.83</td>\n",
       "      <td>랜드마크 신성한 종교적인</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>완산공원</td>\n",
       "      <td>4.65</td>\n",
       "      <td>자연   공원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>용눈이오름</td>\n",
       "      <td>4.87</td>\n",
       "      <td>자연 공원 화산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>명동 성당</td>\n",
       "      <td>4.64</td>\n",
       "      <td>랜드마크 신성한 종교적인 교회 성당</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>익산미륵사지</td>\n",
       "      <td>4.46</td>\n",
       "      <td>랜드마크 신성한 종교적인</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>수도사</td>\n",
       "      <td>4.50</td>\n",
       "      <td>랜드마크 역사적인 신성한 종교적인</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            names  ratings                  keywords\n",
       "0     이천 세계 도자 센터     4.75               전문  박물관    \n",
       "1    신세계 백화점 센텀시티     4.48               쇼핑 백화점     \n",
       "2             미륵산     4.66       자연 공원 산 하이킹트레일     \n",
       "3         성남 아트센터     4.62            즐길거리  랜드마크    \n",
       "4             관촉사     4.83        랜드마크 신성한 종교적인     \n",
       "..            ...      ...                       ...\n",
       "175          완산공원     4.65               자연   공원    \n",
       "176         용눈이오름     4.87             자연 공원 화산     \n",
       "177         명동 성당     4.64  랜드마크 신성한 종교적인 교회 성당     \n",
       "178        익산미륵사지     4.46        랜드마크 신성한 종교적인     \n",
       "179           수도사     4.50   랜드마크 역사적인 신성한 종교적인     \n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['keywords'][data['keywords'].isna()] = ''    # NaN값을 빈 문자열로 대체\n",
    "\n",
    "def preprocess(string):\n",
    "    \n",
    "# '/', '&' 같은 문자 제거\n",
    "# '장소', '및', '전문', '시설' 등과 같은 수식어 제거    \n",
    "# 필요한경우 띄어쓰기 제거 (e.g. 인근 지역 -> 인근지역)\n",
    "\n",
    "    # 공통\n",
    "    \n",
    "    string = string.replace(' /', '')\n",
    "    string = string.replace(' &', '')\n",
    "    string = string.replace(' 및', '')\n",
    "    string = string.replace('아쿠아리움', '수족관') # 중복제거를 위해 아쿠아리움을 수족관으로 통일\n",
    "    \n",
    "    # main_category\n",
    "    \n",
    "    string = string.replace('보트 투어', '보트투어')\n",
    "    string = string.replace('수상 스포츠', '수상스포츠')\n",
    "    string = string.replace('즐길 거리', '즐길거리')\n",
    "    string = string.replace('야외 활동', '야외활동')\n",
    "    string = string.replace('여행자 자료', '여행자자료')\n",
    "\n",
    "    # keywords\n",
    "\n",
    "    string = string.replace('쇼핑몰', '쇼핑')\n",
    "    string = string.replace('전문 박물관', '전문박물관 박물관')\n",
    "    string = string.replace('어린이 박물관', '어린이박물관 박물관')\n",
    "    string = string.replace('자연사 박물관', '자연사박물관 박물관')\n",
    "    string = string.replace('군사 박물관', '군사박물관 박물관')\n",
    "    string = string.replace(' 장소', '') # 종교적인 장소, 교육적인 장소\n",
    "    string = string.replace('인근 지역', '인근지역')\n",
    "    string = string.replace('경관이 좋은 산책로', '경관좋은산책로')\n",
    "    string = string.replace('유서 깊은 산책로', '유서깊은산책로')\n",
    "    string = string.replace('공공기관 건물', '공공기관건물')\n",
    "    string = string.replace('고대 유적', '고대유적')\n",
    "    string = string.replace('군사 기지', '군사기지')\n",
    "    string = string.replace('자동차 경주장', '자동차경주장')\n",
    "    string = string.replace('절경 드라이브 코스', '절경드라이브코스')\n",
    "    string = string.replace('하이킹 트레일', '하이킹트레일')\n",
    "    string = string.replace('야생동물 서식지', '야생동물서식지')\n",
    "    string = string.replace('엔터테인먼트 센터', '엔터테인먼트센터')\n",
    "    string = string.replace('도자기 스튜디오', '도자기스튜디오')\n",
    "    string = string.replace('방 탈출 게임', '방탈출게임 게임')\n",
    "    string = string.replace('기타 놀이', '게임') \n",
    "    string = string.replace('미니 골프', '미니골프')\n",
    "    string = string.replace('물건 찾기 게임', '물건찾기게임 게임')\n",
    "    string = string.replace('테마 파크', '테마파크')\n",
    "    string = string.replace('대중교통 시스템', '대중교통시스템')\n",
    "    \n",
    "    return string\n",
    "\n",
    "data['main_category'] = data['main_category'].apply(preprocess)\n",
    "data['keywords'] = data['keywords'].apply(preprocess)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def leave_space(string):\n",
    "    return ' ' + string\n",
    "\n",
    "data['keywords_aggregated'] = data['main_category'] + data['keywords'].apply(leave_space)\n",
    "\n",
    "data = data.drop(['main_category', 'keywords'], axis=1)\n",
    "\n",
    "data = data.rename(columns = {'keywords_aggregated' : 'keywords'})\n",
    "\n",
    "\n",
    "# 중복되는 단어 처리\n",
    "\n",
    "def duplicates_handle(string):\n",
    "    string_list = string.split(' ')\n",
    "    \n",
    "    tmp = []\n",
    "    \n",
    "    to_del = []\n",
    "    \n",
    "    for val in string_list:\n",
    "        if string_list.count(val)!=1:\n",
    "            to_del.append(val)\n",
    "            tmp.append(val)\n",
    "\n",
    "    for val in to_del:\n",
    "        string = string.replace(val, '')\n",
    "    \n",
    "    tmp_str = ' '\n",
    "    \n",
    "    for val in list(set(tmp)):\n",
    "        tmp_str = tmp_str + val\n",
    "    \n",
    "    string = string + tmp_str\n",
    "    \n",
    "    return string\n",
    "\n",
    "\n",
    "words = ['스포츠', '게임', '박물관', '공원', '쇼핑']\n",
    "\n",
    "for word in words:\n",
    "    data['keywords'] = data['keywords'].apply(duplicates_handle)\n",
    "\n",
    "                   \n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
