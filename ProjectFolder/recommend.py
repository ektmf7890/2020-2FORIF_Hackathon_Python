
import pandas as pd
import numpy as np
from ast import literal_eval
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import warnings
warnings.filterwarnings("ignore")
import random

data=pd.read_csv('Tripadvisor_crawling.csv', usecols=['names', 'main_category', 'ratings', 'keywords'])

data['keywords'][data['keywords'].isna()] = ''    # NaNê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´

def preprocess(string):
    
# '/', '&' ê°™ì€ ë¬¸ì ì œê±°
# 'ì¥ì†Œ', 'ë°', 'ì „ë¬¸', 'ì‹œì„¤' ë“±ê³¼ ê°™ì€ ìˆ˜ì‹ì–´ ì œê±°    
# í•„ìš”í•œê²½ìš° ë„ì–´ì“°ê¸° ì œê±° (e.g. ì¸ê·¼ ì§€ì—­ -> ì¸ê·¼ì§€ì—­)

    # ê³µí†µ
    
    string = string.replace(' /', '')
    string = string.replace(' &', '')
    string = string.replace(' ë°', '')
    string = string.replace('ì•„ì¿ ì•„ë¦¬ì›€', 'ìˆ˜ì¡±ê´€') # ì¤‘ë³µì œê±°ë¥¼ ìœ„í•´ ì•„ì¿ ì•„ë¦¬ì›€ì„ ìˆ˜ì¡±ê´€ìœ¼ë¡œ í†µì¼
    
    # main_category
    
    string = string.replace('ë³´íŠ¸ íˆ¬ì–´', 'ë³´íŠ¸íˆ¬ì–´')
    string = string.replace('ìˆ˜ìƒ ìŠ¤í¬ì¸ ', 'ìˆ˜ìƒìŠ¤í¬ì¸ ')
    string = string.replace('ì¦ê¸¸ ê±°ë¦¬', 'ì¦ê¸¸ê±°ë¦¬')
    string = string.replace('ì•¼ì™¸ í™œë™', 'ì•¼ì™¸í™œë™')
    string = string.replace('ì—¬í–‰ì ìë£Œ', 'ì—¬í–‰ììë£Œ')
    
    # keywords

    string = string.replace('ì‡¼í•‘ëª°', 'ì‡¼í•‘')
    string = string.replace('ì „ë¬¸ ë°•ë¬¼ê´€', 'ì „ë¬¸ë°•ë¬¼ê´€ ë°•ë¬¼ê´€')
    string = string.replace('ì–´ë¦°ì´ ë°•ë¬¼ê´€', 'ì–´ë¦°ì´ë°•ë¬¼ê´€ ë°•ë¬¼ê´€')
    string = string.replace('ìì—°ì‚¬ ë°•ë¬¼ê´€', 'ìì—°ì‚¬ë°•ë¬¼ê´€ ë°•ë¬¼ê´€')
    string = string.replace('êµ°ì‚¬ ë°•ë¬¼ê´€', 'êµ°ì‚¬ë°•ë¬¼ê´€ ë°•ë¬¼ê´€')
    string = string.replace(' ì¥ì†Œ', '') # ì¢…êµì ì¸ ì¥ì†Œ, êµìœ¡ì ì¸ ì¥ì†Œ
    string = string.replace('ì¸ê·¼ ì§€ì—­', 'ì¸ê·¼ì§€ì—­')
    string = string.replace('ê²½ê´€ì´ ì¢‹ì€ ì‚°ì±…ë¡œ', 'ê²½ê´€ì¢‹ì€ì‚°ì±…ë¡œ')
    string = string.replace('ìœ ì„œ ê¹Šì€ ì‚°ì±…ë¡œ', 'ìœ ì„œê¹Šì€ì‚°ì±…ë¡œ')
    string = string.replace('ê³µê³µê¸°ê´€ ê±´ë¬¼', 'ê³µê³µê¸°ê´€ê±´ë¬¼')
    string = string.replace('ê³ ëŒ€ ìœ ì ', 'ê³ ëŒ€ìœ ì ')
    string = string.replace('êµ°ì‚¬ ê¸°ì§€', 'êµ°ì‚¬ê¸°ì§€')
    string = string.replace('ìë™ì°¨ ê²½ì£¼ì¥', 'ìë™ì°¨ê²½ì£¼ì¥')
    string = string.replace('ì ˆê²½ ë“œë¼ì´ë¸Œ ì½”ìŠ¤', 'ì ˆê²½ë“œë¼ì´ë¸Œì½”ìŠ¤')
    string = string.replace('í•˜ì´í‚¹ íŠ¸ë ˆì¼', 'í•˜ì´í‚¹íŠ¸ë ˆì¼')
    string = string.replace('ì•¼ìƒë™ë¬¼ ì„œì‹ì§€', 'ì•¼ìƒë™ë¬¼ì„œì‹ì§€')
    string = string.replace('ì—”í„°í…Œì¸ë¨¼íŠ¸ ì„¼í„°', 'ì—”í„°í…Œì¸ë¨¼íŠ¸ì„¼í„°')
    string = string.replace('ë„ìê¸° ìŠ¤íŠœë””ì˜¤', 'ë„ìê¸°ìŠ¤íŠœë””ì˜¤')
    string = string.replace('ë°© íƒˆì¶œ ê²Œì„', 'ë°©íƒˆì¶œê²Œì„ ê²Œì„')
    string = string.replace('ê¸°íƒ€ ë†€ì´', 'ê²Œì„') 
    string = string.replace('ë¯¸ë‹ˆ ê³¨í”„', 'ë¯¸ë‹ˆê³¨í”„')
    string = string.replace('ë¬¼ê±´ ì°¾ê¸° ê²Œì„', 'ë¬¼ê±´ì°¾ê¸°ê²Œì„ ê²Œì„')
    string = string.replace('í…Œë§ˆ íŒŒí¬', 'í…Œë§ˆíŒŒí¬')
    string = string.replace('ëŒ€ì¤‘êµí†µ ì‹œìŠ¤í…œ', 'ëŒ€ì¤‘êµí†µì‹œìŠ¤í…œ')
    
    return string

data['main_category'] = data['main_category'].apply(preprocess)
data['keywords'] = data['keywords'].apply(preprocess)

def leave_space(string):
    return ' ' + string

data['keywords_aggregated'] = data['main_category'] + data['keywords'].apply(leave_space)

data = data.drop(['main_category', 'keywords'], axis=1)

data = data.rename(columns = {'keywords_aggregated' : 'keywords'})


# ì¤‘ë³µë˜ëŠ” ë‹¨ì–´ ì²˜ë¦¬

def duplicates_handle(string):
    string_list = string.split(' ')
    
    tmp = []
    
    to_del = []
    
    for val in string_list:
        if string_list.count(val)!=1:
            to_del.append(val)
            tmp.append(val)

    for val in to_del:
        string = string.replace(val, '')
    
    tmp_str = ' '
    
    for val in list(set(tmp)):
        tmp_str = tmp_str + val
    
    string = string + tmp_str
    
    return string


words = ['ìŠ¤í¬ì¸ ', 'ê²Œì„', 'ë°•ë¬¼ê´€', 'ê³µì›', 'ì‡¼í•‘']

for word in words:
    data['keywords'] = data['keywords'].apply(duplicates_handle)


count_vector = CountVectorizer(ngram_range=(1, 10))
c_vector_keywords = count_vector.fit_transform(data['keywords'])

keyword_c_sim = cosine_similarity(c_vector_keywords, c_vector_keywords).argsort()[:, ::-1]
keyword_c_sim.shape


def get_recommend_trip_list(df, place, numb, top=30):
    '''df --> ë°ì´í„°í”„ë ˆì„
    place --> ë¹„ìŠ·í•œ ì—¬í–‰ì§€ ì°¾ê³ ì‹¶ì€ íŠ¹ì • ì—¬í–‰ì§€ë¥¼ string í˜•ì‹ìœ¼ë¡œ ì…ë ¥
    numb --> ì¶”ì²œë°›ê³ ì‹¶ì€ ì—¬í–‰ì§€ ê°œìˆ˜'''
    #ë¹„ìŠ·í•œ ì—¬í–‰ì§€ë¥¼ ì°¾ê³  ì‹¶ì€ 'íŠ¹ì • ì—¬í–‰ì§€'ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
    target_place_index = df[df['names'] == place].index.values
    #ë¹„ìŠ·í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ì—¬í–‰ì§€ë“¤ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
    sim_index = keyword_c_sim[target_place_index, :top].reshape(-1)
    #ìê¸°ìì‹  ì—†ì• ê¸°
    sim_index = sim_index[sim_index != target_place_index]
    #ì¶”ì¶œí•œ ì—¬í–‰ì§€ë¥¼ data frameìœ¼ë¡œ ë§Œë“¤ê³  ë³„ì (ratings) ìˆœìœ¼ë¡œ ì •ë ¬í•œ ë’¤ return
    result = df.iloc[sim_index].sort_values('ratings', ascending=False)[:numb]

    return result

num_of_sites = data.shape[0]
has_been_displayed = list(np.zeros(num_of_sites))
chosen_sites = []

def add_site_info(i, choices):
    if has_been_displayed[i] == 0:
        site_info = {
            'index': i,
            'name': data.iloc[i, :]['names'],
            'keywords': data.iloc[i, :]['keywords'],
            'ratings': data.iloc[i, :]['ratings']
        }
        choices.append(site_info)
        has_been_displayed[i] = 1


def print_site_info(site, num=None):
    if num:
        print('{:=^30}'.format(f'<{site["name"]}({num})>'))
        print(site['keywords'], end='\n\n')
    else:
        print('{:=^30}'.format(f'<{site["name"]}>'))
        print(site['keywords'])
        print(f'ë³„ì : {round(site["ratings"], 2)}', end='\n\n')


def display_choices():
    choices = []
    
    for i in random.sample(range(0, num_of_sites), 10):
        add_site_info(i, choices)
        
    while len(choices) < 10:
        add_site_info(i, choices)

    num = 1
    for choice in choices:
        print_site_info(choice, num)
        num += 1
    return choices

indices = pd.Series(data.index, index=data['names'])
def recommend():
    print('\n\nâœˆâœˆâœˆâœˆâœˆâœˆ ì—¬í–‰ì§€ì¶”ì²œí•´ë“€ì˜¤ âœˆâœˆâœˆâœˆâœˆâœˆ\n ë‹¤ìŒ ì—¬í–‰ì§€ ì¤‘ ì¦ê²ê²Œ ë‹¤ë…€ì™”ë˜ ì ì´ ìˆëŠ” ì—¬í–‰ì§€ê°€ ìˆë‹¤ë©´ ì„ íƒí•´ì£¼ì„¸ìš”ğŸ˜')

    while len(chosen_sites) < 5:
        print(f'\n{5-len(chosen_sites)}ê°œ ì´ìƒì„ ë” ì„ íƒí•˜ì…”ì•¼í•´ìš”ğŸ˜‰!\n')
        choices = display_choices()
        input_list = list(map(int, input("ì¢‹ì•˜ë˜ ì—¬í–‰ì§€(ì…ë ¥: 1 3 5, ì—†ìœ¼ë©´ 0) : ").split()))
        
        for idx in input_list:
            if idx != 0:
                chosen_sites.append(choices[idx-1])
        
    print("\n\nğŸ‡ì—¬í–‰ì§€ ì¶”ì²œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!ğŸ‡\n")
    for site in chosen_sites:
        print(f"Because you liked {site['name']}...")
        sim_site_list = get_recommend_trip_list(df=data, place=site['name'], numb=3)
        
        for i in range(3):
            sim_site = sim_site_list.iloc[i]
            sim_dict = {
                'name' : sim_site['names'],
                'keywords': sim_site['keywords'],
                'ratings': sim_site['ratings']
            }
            print_site_info(sim_dict)
        # for sim_site in sim_site_list:
        #     print(sim_site)
        #     idx = indices[sim_site]
        #     site = {
        #         'name': data.iloc[idx, :]['names'],
        #         'keywords': data.iloc[idx, :]['keywords'],
        #         'ratings': data.iloc[idx, :]['ratings']
        #     }
        #     print_site_info(site)
        print()
            
        
recommend()
