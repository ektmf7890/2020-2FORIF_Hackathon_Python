{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Tripadvisor_crawling.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9b4311a6f874>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tripadvisor_crawling.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'main_category'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ratings'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'keywords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alisa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alisa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alisa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alisa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alisa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Tripadvisor_crawling.csv'"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('Tripadvisor_crawling.csv', usecols=['names', 'main_category', 'ratings', 'keywords'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['keywords'][data['keywords'].isna()] = ''    # NaN값을 빈 문자열로 대체\n",
    "\n",
    "def preprocess(string):\n",
    "    \n",
    "# '/', '&' 같은 문자 제거\n",
    "# '장소', '및', '전문', '시설' 등과 같은 수식어 제거    \n",
    "# 필요한경우 띄어쓰기 제거 (e.g. 인근 지역 -> 인근지역)\n",
    "\n",
    "    # 공통\n",
    "    \n",
    "    string = string.replace(' /', '')\n",
    "    string = string.replace(' &', '')\n",
    "    string = string.replace(' 및', '')\n",
    "    string = string.replace('아쿠아리움', '수족관') # 중복제거를 위해 아쿠아리움을 수족관으로 통일\n",
    "    \n",
    "    # main_category\n",
    "    \n",
    "    string = string.replace('보트 투어', '보트투어')\n",
    "    string = string.replace('수상 스포츠', '수상스포츠')\n",
    "    string = string.replace('즐길 거리', '즐길거리')\n",
    "    string = string.replace('야외 활동', '야외활동')\n",
    "    string = string.replace('여행자 자료', '여행자자료')\n",
    "\n",
    "    # keywords\n",
    "\n",
    "    string = string.replace('쇼핑몰', '쇼핑')\n",
    "    string = string.replace('전문 박물관', '전문박물관 박물관')\n",
    "    string = string.replace('어린이 박물관', '어린이박물관 박물관')\n",
    "    string = string.replace('자연사 박물관', '자연사박물관 박물관')\n",
    "    string = string.replace('군사 박물관', '군사박물관 박물관')\n",
    "    string = string.replace(' 장소', '') # 종교적인 장소, 교육적인 장소\n",
    "    string = string.replace('인근 지역', '인근지역')\n",
    "    string = string.replace('경관이 좋은 산책로', '경관좋은산책로')\n",
    "    string = string.replace('유서 깊은 산책로', '유서깊은산책로')\n",
    "    string = string.replace('공공기관 건물', '공공기관건물')\n",
    "    string = string.replace('고대 유적', '고대유적')\n",
    "    string = string.replace('군사 기지', '군사기지')\n",
    "    string = string.replace('자동차 경주장', '자동차경주장')\n",
    "    string = string.replace('절경 드라이브 코스', '절경드라이브코스')\n",
    "    string = string.replace('하이킹 트레일', '하이킹트레일')\n",
    "    string = string.replace('야생동물 서식지', '야생동물서식지')\n",
    "    string = string.replace('엔터테인먼트 센터', '엔터테인먼트센터')\n",
    "    string = string.replace('도자기 스튜디오', '도자기스튜디오')\n",
    "    string = string.replace('방 탈출 게임', '방탈출게임 게임')\n",
    "    string = string.replace('기타 놀이', '게임') \n",
    "    string = string.replace('미니 골프', '미니골프')\n",
    "    string = string.replace('물건 찾기 게임', '물건찾기게임 게임')\n",
    "    string = string.replace('테마 파크', '테마파크')\n",
    "    string = string.replace('대중교통 시스템', '대중교통시스템')\n",
    "    \n",
    "    return string\n",
    "\n",
    "data['main_category'] = data['main_category'].apply(preprocess)\n",
    "data['keywords'] = data['keywords'].apply(preprocess)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def leave_space(string):\n",
    "    return ' ' + string\n",
    "\n",
    "data['keywords_aggregated'] = data['main_category'] + data['keywords'].apply(leave_space)\n",
    "\n",
    "data = data.drop(['main_category', 'keywords'], axis=1)\n",
    "\n",
    "data = data.rename(columns = {'keywords_aggregated' : 'keywords'})\n",
    "\n",
    "\n",
    "# 중복되는 단어 처리\n",
    "\n",
    "def duplicates_handle(string):\n",
    "    string_list = string.split(' ')\n",
    "    \n",
    "    tmp = []\n",
    "    \n",
    "    to_del = []\n",
    "    \n",
    "    for val in string_list:\n",
    "        if string_list.count(val)!=1:\n",
    "            to_del.append(val)\n",
    "            tmp.append(val)\n",
    "\n",
    "    for val in to_del:\n",
    "        string = string.replace(val, '')\n",
    "    \n",
    "    tmp_str = ' '\n",
    "    \n",
    "    for val in list(set(tmp)):\n",
    "        tmp_str = tmp_str + val\n",
    "    \n",
    "    string = string + tmp_str\n",
    "    \n",
    "    return string\n",
    "\n",
    "\n",
    "words = ['스포츠', '게임', '박물관', '공원', '쇼핑']\n",
    "\n",
    "for word in words:\n",
    "    data['keywords'] = data['keywords'].apply(duplicates_handle)\n",
    "\n",
    "                   \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer(ngram_range=(1, 10))\n",
    "c_vector_keywords = count_vector.fit_transform(data['keywords'])\n",
    "c_vector_keywords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vector_keywords.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_c_sim = cosine_similarity(c_vector_keywords, c_vector_keywords).argsort()[:, ::-1]\n",
    "keyword_c_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommend_trip_list(df, place, numb, top=30):\n",
    "    '''df --> 데이터프레임\n",
    "    place --> 비슷한 여행지 찾고싶은 특정 여행지를 string 형식으로 입력\n",
    "    numb --> 추천받고싶은 여행지 개수'''\n",
    "    #비슷한 여행지를 찾고 싶은 '특정 여행지'의 인덱스 추출\n",
    "    target_place_index = df[df['names'] == place].index.values\n",
    "    #비슷한 코사인 유사도를 가진 여행지들의 인덱스 추출\n",
    "    sim_index = keyword_c_sim[target_place_index, :top].reshape(-1)\n",
    "    #자기자신 없애기\n",
    "    sim_index = sim_index[sim_index != target_place_index]\n",
    "    #추출한 여행지를 data frame으로 만들고 별점(ratings) 순으로 정렬한 뒤 return\n",
    "    result = df.iloc[sim_index].sort_values('ratings', ascending=False)[:numb]\n",
    "    print(len(result))\n",
    "    return result\n",
    "\n",
    "# 테스트\n",
    "get_recommend_trip_list(df=data, place='익산미륵사지', numb=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
